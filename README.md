# Прогнозування сепсису: регресійний аналіз даних лікарні Гопкінса

## Вступ

Цей блокнот представляє аналіз та моделювання даних для прогнозування сепсису у пацієнтів на основі даних лікарні Гопкінса. Сепсис — це небезпечний для життя стан, який виникає, коли організм надмірно реагує на інфекцію, що може призвести до пошкодження тканин, відмови органів і смерті.

**Мета аналізу**: Створити модель машинного навчання, яка може точно передбачити, чи розвинеться у пацієнта сепсис на основі наявних медичних показників.

## Терміни та поняття

- **Сепсис** — небезпечна для життя системна запальна реакція на інфекцію, яка може призвести до пошкодження органів, шоку та смерті.
- **Регресійний аналіз** — статистичний метод, який дозволяє встановити залежність між залежною змінною та незалежними змінними.
- **Бінарна класифікація** — тип завдання машинного навчання, де цільова змінна має лише два можливі значення (у нашому випадку "Позитивний" або "Негативний" щодо сепсису).
- **F1 Score** — метрика, яка представляє гармонійне середнє між точністю (precision) та повнотою (recall), використовується для оцінки моделей класифікації, особливо з незбалансованими класами.
- **SMOTE (Synthetic Minority Over-sampling Technique)** — метод вирішення проблеми незбалансованих класів шляхом створення синтетичних прикладів міноритарного класу.
- **ROC-крива (Receiver Operating Characteristic)** — графік, що ілюструє діагностичну здатність бінарного класифікатора при зміні порогу дискримінації.
- **AUC (Area Under the Curve)** — площа під ROC-кривою, яка є мірою продуктивності моделі класифікації.

## Завантаження та огляд даних

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from xgboost import XGBClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc
from imblearn.over_sampling import SMOTE

# Ігнорування попереджень
warnings.filterwarnings('ignore')

# Завантаження даних
train_df = pd.read_csv('https://raw.githubusercontent.com/Stella-Achar-Oiro/Fast-API-for-Sepsis-Prediction-App/refs/heads/main/Paitients_Files_Train.csv')
test_df = pd.read_csv('https://raw.githubusercontent.com/Stella-Achar-Oiro/Fast-API-for-Sepsis-Prediction-App/refs/heads/main/Paitients_Files_Test.csv')
```

Після завантаження даних ми можемо побачити структуру наших датасетів:

```
Тренувальний датасет:
          ID  PRG   PL  PR  SK   TS   M11    BD2  Age  Insurance   Sepssis
0  ICU200010    6  148  72  35    0  33.6  0.627   50          0  Positive
1  ICU200011    1   85  66  29    0  26.6  0.351   31          0  Negative
2  ICU200012    8  183  64   0    0  23.3  0.672   32          1  Positive
3  ICU200013    1   89  66  23   94  28.1  0.167   21          1  Negative
4  ICU200014    0  137  40  35  168  43.1  2.288   33          1  Positive

Тестовий датасет:
          ID  PRG   PL  PR  SK   TS   M11    BD2  Age  Insurance
0  ICU200609    1  109  38  18  120  23.1  0.407   26          1
1  ICU200610    1  108  88  19    0  27.1  0.400   24          1
2  ICU200611    6   96   0   0    0  23.7  0.190   28          1
3  ICU200612    1  124  74  36    0  27.8  0.100   30          1
4  ICU200613    7  150  78  29  126  35.2  0.692   54          0
```

### Аналіз структури даних

Тренувальний датасет містить 599 записів та 11 стовпців:
- `ID` — унікальний ідентифікатор пацієнта
- `PRG` — кількість вагітностей (ймовірно для жінок)
- `PL` — рівень глюкози плазми
- `PR` — діастолічний кров'яний тиск
- `SK` — товщина шкірної складки трицепса
- `TS` — рівень інсуліну в сиворотці
- `M11` — індекс маси тіла
- `BD2` — функція родоводу діабету
- `Age` — вік пацієнта
- `Insurance` — наявність страхування (1 — так, 0 — ні)
- `Sepssis` — цільова змінна (наявність сепсису: Positive/Negative)

Тестовий датасет має подібну структуру, але без цільової змінної `Sepssis`, оскільки він використовується для прогнозування.

### Статистичний опис даних

```
Статистичний опис тренувального датасету:
              PRG          PL          PR          SK          TS         M11         BD2         Age   Insurance
count  599.000000  599.000000  599.000000  599.000000  599.000000  599.000000  599.000000  599.000000  599.000000
mean     3.824708  120.153589   68.732888   20.562604   79.460768   31.920033    0.481187   33.290484    0.686144
std      3.362839   32.682364   19.335675   16.017622  116.576176    8.008227    0.337552   11.828446    0.464447
min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000    0.078000   21.000000    0.000000
25%      1.000000   99.000000   64.000000    0.000000    0.000000   27.100000    0.248000   24.000000    0.000000
50%      3.000000  116.000000   70.000000   23.000000   36.000000   32.000000    0.383000   29.000000    1.000000
75%      6.000000  140.000000   80.000000   32.000000  123.500000   36.550000    0.647000   40.000000    1.000000
max     17.000000  198.000000  122.000000   99.000000  846.000000   67.100000    2.420000   81.000000    1.000000
```

**Інтерпретація статистичного опису**:
- Середній вік пацієнтів становить приблизно 33 роки
- Середній рівень глюкози плазми (PL) становить 120 мг/дл
- Середній індекс маси тіла (M11) становить 31.92, що вказує на ожиріння 1 ступеня
- Приблизно 69% пацієнтів мають страхування (Insurance)

### Перевірка пропущених значень

Перевірка показала, що у наших датасетах немає пропущених значень, що спрощує подальший аналіз:

```
Пропущені значення в тренувальному датасеті:
ID           0
PRG          0
PL           0
PR           0
SK           0
TS           0
M11          0
BD2          0
Age          0
Insurance    0
Sepssis      0
dtype: int64

Пропущені значення в тестовому датасеті:
ID           0
PRG          0
PL           0
PR           0
SK           0
TS           0
M11          0
BD2          0
Age          0
Insurance    0
dtype: int64
```

### Аналіз розподілу класів

```
Розподіл класів в тренувальному датасеті:
Sepssis
Negative    391
Positive    208
Name: count, dtype: int64
Sepssis
Negative    65.275459
Positive    34.724541
Name: proportion, dtype: float64
```

СКРІНШОТ: Розподіл класів сепсису (стовпчикова діаграма)

**Інтерпретація розподілу класів**:
- Дані не збалансовані: 65.3% пацієнтів не мають сепсису (Negative), а 34.7% мають сепсис (Positive)
- Незбалансованість класів може впливати на точність моделі, тому будемо застосовувати техніку SMOTE для балансування класів

### Кореляційний аналіз

СКРІНШОТ: Кореляційна матриця (теплова карта)

**Інтерпретація кореляційної матриці**:
- Спостерігається помірна кореляція між деякими параметрами
- Зокрема, може бути кореляція між рівнем глюкози (PL) та ризиком сепсису
- Також індекс маси тіла (M11) показує певну кореляцію з іншими показниками здоров'я

## Підготовка даних для моделювання

### Розділення даних

```python
# Підготовка даних для моделювання
# Видалення ID колонки
X_train = train_df.drop(['ID', 'Sepssis'], axis=1)
y_train = train_df['Sepssis']

# Перетворення цільової змінної
le = LabelEncoder()
y_train = le.fit_transform(y_train)  # Positive -> 1, Negative -> 0

# Масштабування ознак
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)

# Поділ на тренувальний і валідаційний набори
X_train_set, X_val, y_train_set, y_val = train_test_split(X_train_scaled, y_train, test_size=0.2, random_state=42)
```

**Інтерпретація підготовки даних**:
- Ми видалили стовпець `ID`, оскільки він не має прогностичної цінності
- Перетворили цільову змінну з текстового формату (Positive/Negative) на числовий (1/0) за допомогою LabelEncoder
- Стандартизували ознаки для покращення продуктивності моделей (особливо важливо для логістичної регресії та SVM)
- Розділили дані на тренувальний (80%) та валідаційний (20%) набори для оцінки якості моделей

### Обробка незбалансованості класів за допомогою SMOTE

```python
# Обробка незбалансованості класів за допомогою SMOTE
smote = SMOTE(random_state=42)
X_train_smote, y_train_smote = smote.fit_resample(X_train_set, y_train_set)
```

Результати балансування класів:
```
Розмірність даних після SMOTE:
X_train_smote: (628, 9)
y_train_smote: 628
Розподіл класів: [314 314]
```

**Інтерпретація результатів SMOTE**:
- До застосування SMOTE класи були незбалансовані (65.3% Negative, 34.7% Positive)
- Після застосування SMOTE маємо по 314 зразків кожного класу
- Це допоможе моделям краще навчатися на збалансованих даних і зменшить упередженість до більшого класу

## Навчання та оцінка моделей

Було навчено та оцінено шість різних моделей машинного навчання:

### 1. Логістична регресія

```
=== Логістична регресія ===
Accuracy: 0.7083
Precision: 0.5741
Recall: 0.7209
F1 Score: 0.6392
```

СКРІНШОТ: Матриця помилок для логістичної регресії
СКРІНШОТ: ROC-крива для логістичної регресії

### 2. Дерево рішень

```
=== Дерево рішень ===
Accuracy: 0.6833
Precision: 0.5556
Recall: 0.5814
F1 Score: 0.5682
```

СКРІНШОТ: Матриця помилок для дерева рішень
СКРІНШОТ: ROC-крива для дерева рішень

### 3. Випадковий ліс

```
=== Випадковий ліс ===
Accuracy: 0.7083
Precision: 0.5833
Recall: 0.6512
F1 Score: 0.6154
```

СКРІНШОТ: Матриця помилок для випадкового лісу
СКРІНШОТ: ROC-крива для випадкового лісу

### 4. Градієнтний бустинг

```
=== Градієнтний бустинг ===
Accuracy: 0.7333
Precision: 0.6038
Recall: 0.7442
F1 Score: 0.6667
```

СКРІНШОТ: Матриця помилок для градієнтного бустингу
СКРІНШОТ: ROC-крива для градієнтного бустингу

### 5. XGBoost

```
=== XGBoost ===
Accuracy: 0.7167
Precision: 0.5918
Recall: 0.6744
F1 Score: 0.6304
```

СКРІНШОТ: Матриця помилок для XGBoost
СКРІНШОТ: ROC-крива для XGBoost

### 6. SVM (Support Vector Machine)

```
=== SVM ===
Accuracy: 0.6833
Precision: 0.5490
Recall: 0.6512
F1 Score: 0.5957
```

СКРІНШОТ: Матриця помилок для SVM
СКРІНШОТ: ROC-крива для SVM

## Порівняння моделей

```
Порівняння моделей:
                Модель  Accuracy  Precision    Recall  F1 Score       AUC
3  Градієнтний бустинг  0.733333   0.603774  0.744186  0.666667  0.782845
0  Логістична регресія  0.708333   0.574074  0.720930  0.639175  0.780127
4              XGBoost  0.716667   0.591837  0.674419  0.630435  0.749018
2       Випадковий ліс  0.708333   0.583333  0.651163  0.615385  0.760042
5                  SVM  0.683333   0.549020  0.651163  0.595745  0.724252
1        Дерево рішень  0.683333   0.555556  0.581395  0.568182  0.660828
```

СКРІНШОТ: Порівняння моделей за метриками (сітка графіків)

**Інтерпретація результатів порівняння моделей**:
- Градієнтний бустинг показав найкращі результати за всіма основними метриками:
  - Найвища точність (Accuracy): 73.3%
  - Найвища точність позитивних прогнозів (Precision): 60.4%
  - Найвища повнота (Recall): 74.4%
  - Найвищий F1 Score: 66.7%
  - Найвища площа під ROC-кривою (AUC): 78.3%
- Логістична регресія також показала хороші результати, які лише трохи поступаються градієнтному бустингу
- Дерево рішень показало найгірші результати серед усіх моделей

## Аналіз важливості ознак

```
Важливість ознак:
      Ознака  Важливість
1         PL    0.353799
5        M11    0.224358
7        Age    0.141456
0        PRG    0.080190
6        BD2    0.078750
3         SK    0.052968
2         PR    0.027421
4         TS    0.027237
8  Insurance    0.013821
```

СКРІНШОТ: Важливість ознак для моделі градієнтного бустингу (стовпчикова діаграма)

**Інтерпретація важливості ознак**:
- Рівень глюкози плазми (PL) є найбільш важливою ознакою для прогнозування сепсису з внеском 35.4%
- Індекс маси тіла (M11) є другою за важливістю ознакою з внеском 22.4%
- Вік пацієнта (Age) є третьою за важливістю ознакою з внеском 14.1%
- Наявність страхування (Insurance) має найменший вплив на прогнозування сепсису

Ці результати мають клінічне значення, оскільки підтверджують важливість моніторингу рівня глюкози та індексу маси тіла у пацієнтів для оцінки ризику розвитку сепсису.

## Оптимізація гіперпараметрів найкращої моделі

```
=== Оптимізація гіперпараметрів найкращої моделі ===
Найкращі параметри: {'learning_rate': 0.2, 'max_depth': 7, 'n_estimators': 200}
Найкраща F1-оцінка: 0.8406
Accuracy: 0.6917
Precision: 0.5625
Recall: 0.6279
F1 Score: 0.5934
```

СКРІНШОТ: Матриця помилок для оптимізованої моделі
СКРІНШОТ: ROC-крива для оптимізованої моделі

**Інтерпретація результатів оптимізації**:
- Оптимальні параметри включають високу швидкість навчання (0.2), глибоке дерево (7) та велику кількість дерев (200)
- Під час крос-валідації на тренувальних даних модель досягла високого значення F1-оцінки 0.8406
- Однак на валідаційному наборі продуктивність оптимізованої моделі дещо знизилась (F1 Score: 0.5934)
- Це може свідчити про перенавчання моделі, незважаючи на високу метрику під час пошуку параметрів

## Прогнозування на тестовому наборі даних

```
Результати прогнозування для тестового набору:
          ID Sepssis_Prediction   Probability
0  ICU200609           Negative  8.201175e-08
1  ICU200610           Negative  1.549732e-06
2  ICU200611           Negative  1.063457e-08
3  ICU200612           Negative  7.821414e-03
4  ICU200613           Negative  4.738830e-01
```

**Інтерпретація результатів прогнозування**:
- Для перших 5 пацієнтів з тестового набору модель прогнозує відсутність сепсису (Negative)
- Ймовірності варіюються від дуже низьких (практично нульових) до помірних (0.474 для пацієнта ICU200613)
- Пацієнт ICU200613 має найвищу ймовірність розвитку сепсису серед перших 5 пацієнтів, але все ще нижче порогу класифікації 0.5

## Висновки

1. **Найкраща модель**: Градієнтний бустинг показав найкращі результати для прогнозування сепсису з F1 Score 0.667 та AUC 0.783, що свідчить про хорошу дискримінаційну здатність моделі.

2. **Важливі прогностичні фактори**: Рівень глюкози плазми (PL), індекс маси тіла (M11) та вік пацієнта (Age) є найважливішими факторами для прогнозування сепсису.

3. **Значення для медичної практики**: Результати аналізу можуть допомогти медичним працівникам зосередити увагу на пацієнтах з високим рівнем глюкози та підвищеним індексом маси тіла для раннього виявлення і попередження сепсису.

4. **Обмеження дослідження**:
   - Оптимізована модель показала ознаки перенавчання
   - Обмежена кількість факторів (ознак) для прогнозування
   - Відносно невелика вибірка даних

5. **Напрямки для покращення**:
   - Збір додаткових даних для навчання моделі
   - Включення додаткових клінічних показників
   - Застосування більш складних методів регуляризації для запобігання перенавчанню
   - Випробування інших алгоритмів машинного навчання та ансамблевих методів

## Глосарій термінів

- **Accuracy (Точність)** — відношення кількості правильних прогнозів до загальної кількості прогнозів.
- **Precision (Точність позитивних прогнозів)** — частка правильно ідентифікованих позитивних випадків серед усіх прогнозованих позитивних випадків.
- **Recall (Повнота)** — частка правильно ідентифікованих позитивних випадків серед усіх реальних позитивних випадків.
- **F1 Score** — гармонійне середнє між precision та recall, яке забезпечує збалансовану оцінку моделі.
- **ROC-крива** — графік, що показує ефективність бінарного класифікатора при різних порогах класифікації.
- **AUC (Area Under the Curve)** — числова міра продуктивності класифікатора, рівна площі під ROC-кривою.
- **Градієнтний бустинг** — ансамблевий метод машинного навчання, який послідовно будує прості моделі, кожна з яких компенсує недоліки попередніх.
- **Гіперпараметри** — параметри алгоритму, які встановлюються перед його запуском і не можуть бути вивчені з даних.
- **Перенавчання (Overfitting)** — стан, коли модель занадто добре пристосовується до тренувальних даних і погано узагальнюється на нових даних.

## Посилання

1. [Сепсис: визначення, патофізіологія та раннє розпізнавання](https://www.who.int/news-room/fact-sheets/detail/sepsis)
2. [Градієнтний бустинг - документація scikit-learn](https://scikit-learn.org/stable/modules/ensemble.html#gradient-boosting)
3. [Техніка SMOTE для балансування класів](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTE.html)
4. [Оцінка моделей класифікації: метрики та техніки](https://scikit-learn.org/stable/modules/model_evaluation.html)
5. [Оптимізація гіперпараметрів за допомогою GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)
